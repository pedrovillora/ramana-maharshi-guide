import streamlit as st
import google.generativeai as genai

# 1. CONFIGURACI√ìN DE LA P√ÅGINA
st.set_page_config(
    page_title="Ramana Maharshi AI", 
    page_icon="üßò",
    layout="centered"
)

# Est√©tica simple y espiritual
st.title("üßò Ramana Maharshi AI Guide")
st.markdown("*La respuesta a cada pregunta es: ¬øQui√©n soy yo?*")
st.divider()

# 2. CARGA SEGURA DE API KEY
try:
    # Busca la clave en Settings > Secrets
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception:
    st.error("‚ö†Ô∏è Error: No se encontr√≥ la 'GOOGLE_API_KEY' en los Secrets de Streamlit.")
    st.info("Ve a 'Manage App' > 'Settings' > 'Secrets' y a√±ade: GOOGLE_API_KEY = 'tu_clave'")
    st.stop()

# 3. CONFIGURACI√ìN DEL MODELO (Versi√≥n 2026)
# Usamos gemini-2.0-flash por su velocidad y disponibilidad
model = genai.GenerativeModel('gemini-2.0-flash-lite')

# Instrucci√≥n de personalidad (System Prompt)
SYSTEM_PROMPT = (
    "Eres un gu√≠a espiritual basado exclusivamente en las ense√±anzas de Ramana Maharshi. "
    "Tus respuestas deben ser extremadamente breves, llenas de paz y silencio. "
    "Tu objetivo no es dar informaci√≥n acad√©mica, sino dirigir la mente del usuario "
    "hacia su origen a trav√©s de la auto-indagaci√≥n (Atma-Vichara). "
    "Si el usuario est√° confundido, recu√©rdale investigar qui√©n es el que tiene esa duda."
)

# 4. GESTI√ìN DEL HISTORIAL DE CHAT
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar mensajes previos
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ENTRADA DE PREGUNTAS
if prompt := st.chat_input("Consulta al Silencio..."):
    # Guardar y mostrar mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generar respuesta de la IA
    with st.chat_message("assistant"):
        try:
            # Combinamos la instrucci√≥n con la pregunta para asegurar la personalidad
            full_query = f"{SYSTEM_PROMPT}\n\nUsuario pregunta: {prompt}"
            
            response = model.generate_content(full_query)
            respuesta_texto = response.text
            
            st.markdown(respuesta_texto)
            st.session_state.messages.append({"role": "assistant", "content": respuesta_texto})
            
        except Exception as e:
            st.error(f"El flujo de sabidur√≠a se ha interrumpido: {e}")
